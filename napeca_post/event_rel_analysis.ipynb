{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAPE Calcium Imaging Event-Related Analysis\n",
    "\n",
    "Finds any .tif, .tiff, .h5 files in the requested directory and performs SIMA-based motion correction and fft-based bidirection \n",
    "offset correction, signal extraction, and neuropil correction. This code parallelizes the computation at the session level by passing the multiple file paths (if there are more than one recordings) to the multiprocessing map function. \n",
    "\n",
    "\n",
    "How to run this code\n",
    "------------------------------------\n",
    "\n",
    "__In this jupyter notebook, just run all cells in order (shift + enter).__\n",
    "\n",
    "You can indicate specific files, parameters, and processing steps to include by __editing the python script called files_to_analyze_event.py__ (in the same directory as this script). Once you have specified the files in files_to_analyze.py and saved, run this notebooks' cells, leave the input blank, and press enter; this code will automatically load the information in files_to_analyze_event.py.\n",
    "\n",
    "\n",
    "Required Packages\n",
    "-----------------\n",
    "Python 2.7, seaborn, matplotlib, pandas, scikit-learn\n",
    "\n",
    "Custom code requirements: utils\n",
    "\n",
    "Parameters (Only relevant if using the subfunction batch_process; ignore if using files_to_analyze or using default params by inputting a file directory)\n",
    "----------\n",
    "\n",
    "fname : string\n",
    "    \n",
    "    Base name of the file to analyze (pre-motion corrected file name).\n",
    "\n",
    "fdir : string \n",
    "\n",
    "    Root file directory containing the raw tif, tiff, h5 files. Note: leave off the last backslash. For example: C:\\Users\\my_user\\analyze_sessions\n",
    "    \n",
    "trial_start_end : list of two entries  \n",
    "\n",
    "    Entries can be ints or floats. The first entry is the time in seconds relative to the event/ttl onset for the start of the event analysis window (negative if before the event/ttl onset. The second entry is the time in seconds for the end of the event analysis window. For example if the desired analysis window is 5.5 seconds before event onset and 8 seconds after, `trial_start_end` would be [-5.5, 8].  \n",
    "    \n",
    "baseline_end : int/float  \n",
    "\n",
    "    Time in seconds for the end of the baseline epoch. By default, the baseline epoch start time will be the first entry ot `trial_start_end`. This baseline epoch is used for calculating baseline normalization metrics.\n",
    "    \n",
    "event_dur : int/float  \n",
    "\n",
    "    Time in seconds representing how long the behavioral event or stimulation, etc. lasts.\n",
    "\n",
    "flag_npil_corr : boolean  \n",
    "\n",
    "    Set as True if user would like to load in neuropil corrected data from the preprocessing pipeline. Must have a \\*\\_neuropil\\_corrected_signal_* file in the directory. If set as False, just use the extracted_signal file.\n",
    "    \n",
    "flag_zscore : boolean  \n",
    "\n",
    "    Set as True if analyzed data should be baseline z-scored on a trial level.  \n",
    "\n",
    "flag_sort_rois : boolean\n",
    "\n",
    "    Set as True to sort ROIs on the y axis of heatmaps. This works with `user_sort_method` and `roi_sort_cond` for specifying details of sorting.\n",
    "\n",
    "flag_roi_trial_avg_errbar : boolean  \n",
    "\n",
    "    Set as True to set standard error of mean shaded portions for line plots of trial-averaged activity.   \n",
    "\n",
    "flag_save_figs : boolean  \n",
    "\n",
    "    Set as True to save figures as JPG and vectorized formats.  \n",
    "\n",
    "interesting_rois : list of ints  \n",
    "\n",
    "    All entries are indices for ROIs that will be marked in heatmaps by arrows.  \n",
    "\n",
    "Optional Parameters (Only relevant if using batch_process)\n",
    "-------------------\n",
    "\n",
    "user_sort_method : string\n",
    "    \n",
    "    Takes the strings 'peak_time' or 'max_value'\n",
    "    \n",
    "    \n",
    "roi_sort_cond : string\n",
    "    for roi-resolved heatmaps, which condition to sort ROIs by\n",
    "    \n",
    "    Defaults to first condition available\n",
    "    \n",
    "Output\n",
    "-------\n",
    "\n",
    "output_images : folder containing images  \n",
    "    \n",
    "    You will also find a folder containing plots that reflect how each executed preprocessing step performed. Examples are mean images for motion corrected data, ROI masks overlaid on mean images, extracted signals for each ROI, etc..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import pickle\n",
    "import json\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "#important for text to be detected when importing saved figures into illustrator\n",
    "matplotlib.rcParams['pdf.fonttype']=42\n",
    "matplotlib.rcParams['ps.fonttype']=42\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple class to update limits as you go through iterations of data\n",
    "# first call update_lims(first_lims)\n",
    "# then update_lims.update(new_lims)\n",
    "# update_lims.output() outputs lims\n",
    "class update_lims:\n",
    "    \n",
    "    def __init__(self, lims):\n",
    "        self.lims = lims\n",
    "        \n",
    "    \n",
    "    def update(self, new_lims):\n",
    "        if self.lims[0] > new_lims[0]:\n",
    "            self.lims[0] = new_lims[0]\n",
    "        \n",
    "        if self.lims[1] < new_lims[1]:\n",
    "            self.lims[1] = new_lims[1]\n",
    "\n",
    "    def output(self):\n",
    "        return self.lims\n",
    "    \n",
    "    \n",
    "# find 2D subplot index based on a numerical incremented index (ie. idx=3 would be (2,1) for a 2x2 subplot figure)     \n",
    "def subplot_loc(idx, num_rows, num_col):\n",
    "    if n_rows == 1:\n",
    "        subplot_index = idx\n",
    "    else:\n",
    "        subplot_index = np.unravel_index(idx, (n_rows, int(n_columns))) # turn int index to a tuple of array coordinates\n",
    "    return subplot_index\n",
    "\n",
    "\n",
    "def get_cmap(n, name='plasma'):\n",
    "    '''Returns a function that maps each index in 0, 1, ..., n-1 to a distinct \n",
    "    RGB color; the keyword argument name must be a standard mpl colormap name.'''\n",
    "    return plt.cm.get_cmap(name, n)\n",
    "\n",
    "\n",
    "def is_all_nans(vector):\n",
    "    \"\"\"\n",
    "    checks if series or vector contains all nans; returns boolean. Used to identify and exclude all-nan rois\n",
    "    \"\"\"\n",
    "    if isinstance(vector, pd.Series):\n",
    "        vector = vector.values\n",
    "    return np.isnan(vector).all()\n",
    "\n",
    "# declare some fixed constant variables\n",
    "axis_label_size = 15\n",
    "tick_font_size = 14 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "User-defined variables\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def define_params(method = 'single'):\n",
    "    \n",
    "    fparams = {}\n",
    "    \n",
    "    if method == 'single':\n",
    "        \n",
    "        fparams['fname'] = 'VJ_OFCVTA_7_260_D6'   # \n",
    "        fparams['fdir'] = r'C:\\2pData\\Vijay data\\VJ_OFCVTA_7_D8_trained' #  \n",
    "        fparams['flag_save_figs'] = False\n",
    "        \n",
    "        # set the sampling rate\n",
    "        fparams['fs'] = 5 # this gets overwritten by json fs variable (if it exists) that is saved in preprocessing\n",
    "        json_fpath = os.path.join(fparams['fdir'], fparams['fname']+\".json\")\n",
    "        if os.path.exists(json_fpath):\n",
    "            json_data = utils.open_json(json_fpath)\n",
    "            if 'fs' in json_data:\n",
    "                fparams['fs'] = json_data['fs']\n",
    "\n",
    "        fparams['selected_conditions'] = ['plus', 'minus'] # set to None if want to include all conditions from behav data\n",
    "        \n",
    "        # trial windowing \n",
    "        fparams['trial_start_end'] = [-2, 7]\n",
    "        fparams['baseline_end'] = -0.2\n",
    "        fparams['event_dur'] = 0.1#0.46 # duration of stim/event in seconds\n",
    "        fparams['event_sort_win'] = [0, 7]\n",
    "\n",
    "        # session info\n",
    "        fparams['opto_blank_frame'] = False # if PMTs were blanked during stim, set stim times to nan (instead of 0)\n",
    "        \n",
    "        # analysis and plotting arguments\n",
    "        fparams['flag_npil_corr'] = True # declare which data to load in\n",
    "        fparams['flag_zscore'] = True # whether or not to z-score data for plots\n",
    "        \n",
    "        # ROI sorting \n",
    "        fparams['flag_sort_rois'] = True\n",
    "        if fparams['flag_sort_rois']:\n",
    "            fparams['user_sort_method'] = 'max_value' # peak_time or max_value\n",
    "            fparams['roi_sort_cond'] = 'plus' # for roi-resolved heatmaps, which condition to sort ROIs by\n",
    "            \n",
    "        # errorbar and saving figures\n",
    "        fparams['flag_roi_trial_avg_errbar'] = True # toggle to show error bar on roi- and trial-averaged traces\n",
    "        fparams['flag_trial_avg_errbar'] = True # toggle to show error bars on the trial-avg traces\n",
    "        fparams['interesting_rois'] = [] #[ 0, 1, 2, 23, 22, 11, 9, 5, 6, 7, 3, 4, 8, 12, 14, 15, 16, 17] # [35, 30, 20, 4] #\n",
    "    \n",
    "    elif method == 'f2a': # if string is empty, load predefined list of files in files_to_analyze_event\n",
    "\n",
    "        fparams = files_to_analyze_event.define_fparams()\n",
    "\n",
    "    elif method == 'root_dir':\n",
    "        \n",
    "        pass\n",
    "\n",
    "    with open(os.path.join(fparams['fdir'], 'event_analysis_fparam'), 'w') as fp:\n",
    "        json.dump(fparams, fp)\n",
    "    \n",
    "    return fparams\n",
    "\n",
    "fparams = define_params(method = 'single') # options are 'single', 'f2a', 'root_dir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare paths\n",
    "if fparams['flag_npil_corr'] == True:\n",
    "    signals_fpath = os.path.join(fparams['fdir'], \"{}_neuropil_corrected_signals*\".format(fparams['fname']))\n",
    "    \n",
    "else:\n",
    "    signals_fpath = os.path.join(fparams['fdir'], \"*_extractedsignals*\")\n",
    "\n",
    "save_dir = os.path.join(fparams['fdir'], 'event_rel_analysis')\n",
    "\n",
    "utils.check_exist_dir(save_dir); # make the save directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create variables that reference samples and times for slicing and plotting the data\n",
    "\n",
    "trial_start_end_sec = np.array(fparams['trial_start_end']) # trial windowing in seconds relative to ttl-onset/trial-onset, in seconds\n",
    "baseline_start_end_sec = np.array([trial_start_end_sec[0], fparams['baseline_end']])\n",
    "\n",
    "# convert times to samples and get sample vector for the trial \n",
    "trial_begEnd_samp = trial_start_end_sec*fparams['fs'] # turn trial start/end times to samples\n",
    "trial_svec = np.arange(trial_begEnd_samp[0], trial_begEnd_samp[1])\n",
    "# and for baseline period\n",
    "baseline_begEnd_samp = baseline_start_end_sec*fparams['fs']\n",
    "baseline_svec = (np.arange(baseline_begEnd_samp[0], baseline_begEnd_samp[1]+1, 1) - baseline_begEnd_samp[0]).astype('int')\n",
    "\n",
    "# calculate time vector for plot x axes\n",
    "num_samples_trial = len( trial_svec )\n",
    "tvec = np.round(np.linspace(trial_start_end_sec[0], trial_start_end_sec[1], num_samples_trial+1), 2)\n",
    "\n",
    "# find samples and calculations for time 0 for plotting\n",
    "t0_sample = utils.get_tvec_sample(tvec, 0) # grabs the sample index of a given time from a vector of times\n",
    "event_end_sample = int(np.round(t0_sample+fparams['event_dur']*fparams['fs']))\n",
    "event_bound_ratio = [(t0_sample-1)/num_samples_trial , event_end_sample/num_samples_trial] # fraction of total samples for event start and end; only used for plotting line indicating event duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load time-series data\n",
    "glob_signal_files = glob.glob(signals_fpath)\n",
    "if len(glob_signal_files) == 1:\n",
    "    signals = np.squeeze(np.load(glob_signal_files[0]))\n",
    "else:\n",
    "    print('Warning: No or multiple signal files detected; using first detected file')\n",
    "\n",
    "num_rois = signals.shape[0]\n",
    "all_nan_rois = np.where(np.apply_along_axis(is_all_nans, 1, signals)) # find rois with activity as all nans\n",
    "\n",
    "if fparams['opto_blank_frame']:\n",
    "    try:\n",
    "        glob_stim_files = glob.glob(os.path.join(fparams['fdir'], \"{}*_stimmed_frames.pkl\".format(fparams['fname'])))\n",
    "        stim_frames = pickle.load( open( glob_stim_files[0], \"rb\" ) )\n",
    "        signals[:,stim_frames['samples']] = None # blank out stimmed frames\n",
    "        flag_stim = True\n",
    "        print('Detected stim data; replaced stim samples with NaNs')\n",
    "    except:\n",
    "        flag_stim = False\n",
    "        print('Note: No stim preprocessed meta data detected.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load behavioral data and trial info\n",
    "try:\n",
    "    glob_frame_files = glob.glob(os.path.join(fparams['fdir'], \"framenumberforevents_*\")) # look for a file in specified directory\n",
    "    event_frames = pickle.load( open( glob_frame_files[0], \"rb\" ), encoding='latin1' ) # latin1 b/c original pickle made in python 2\n",
    "except:\n",
    "    print('Cannot find behavioral data file or file path is incorrect; utils.extract_trial_data will throw error.')\n",
    "\n",
    "# identify conditions to analyze\n",
    "all_conditions = event_frames.keys()\n",
    "conditions = [ condition for condition in all_conditions if len(event_frames[condition]) > 0 ] # keep conditions that have events\n",
    "\n",
    "conditions.sort()\n",
    "if fparams['selected_conditions']:\n",
    "    conditions = fparams['selected_conditions']\n",
    "\n",
    "cmap_lines = get_cmap(len(conditions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start trial-based preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MAIN data processing function to extract event-centered data\n",
    "\n",
    "extract and save trial data, \n",
    "saved data are in the event_rel_analysis subfolder, a pickle file that contains the extracted trial data\n",
    "\"\"\"\n",
    "data_dict = utils.extract_trial_data(signals, tvec, trial_begEnd_samp, event_frames, \n",
    "                                     conditions, baseline_start_end_samp = baseline_begEnd_samp, save_dir=save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calculate all the color limits for heatmaps; useful for locking color limits across different heatmap subplots\n",
    "\n",
    "# for trial_avg data, get min/max across conditions\n",
    "clims_data = [ np.nanmin( [np.mean(data_dict[key]['data'], axis = 0) for key in data_dict] ), \n",
    "        np.nanmax( [np.mean(data_dict[key]['data'], axis = 0) for key in data_dict] ) ]\n",
    "\n",
    "# for z-scored data, we'd like for the color scale to be centered at 0; first we get color limits\n",
    "tmp_clim = [ np.nanmin( [data_dict[key]['ztrial_avg_data'] for key in data_dict] ), \n",
    "        np.nanmax( [data_dict[key]['ztrial_avg_data'] for key in data_dict] ) ]\n",
    "# then we take the higher of the two magnitudes\n",
    "clims_max = np.max(np.abs(tmp_clim))\n",
    "# and set it as the negative and positive limit for plotting\n",
    "clims_z = [-clims_max*0.5, clims_max*0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot trial-resolved heatmap for each ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subplot_trial_heatmap(data_in, conditions, tvec, event_bound_ratio, clims, n_rows, n_columns, \n",
    "                           save_fig = False, axis_label_size=15):\n",
    "    \n",
    "    \"\"\"\n",
    "    event_bound_ratio\n",
    "    \"\"\"\n",
    "    \n",
    "    for idx_cond, cond in enumerate(conditions):\n",
    "        \n",
    "        # set imshow extent to replace x and y axis ticks/labels\n",
    "        plot_extent = [tvec[0], tvec[-1], 0, data_in[cond]['num_trials']]\n",
    "        \n",
    "        # determine subplot location index\n",
    "        subplot_index = subplot_loc(idx_cond, n_rows, n_columns)\n",
    "        \n",
    "        # prep labels; plot x and y labels for first subplot\n",
    "        if subplot_index == (0, 0) or subplot_index == 0 :\n",
    "            ax[subplot_index].set_ylabel('Trial', fontsize=axis_label_size)\n",
    "            ax[subplot_index].set_xlabel('Time [s]', fontsize=axis_label_size);\n",
    "        ax[subplot_index].tick_params(axis = 'both', which = 'major', labelsize = tick_font_size)\n",
    "        \n",
    "        # prep the data\n",
    "        to_plot = np.squeeze(data_in[cond]['data'][...,iROI,:]) \n",
    "        if len(event_frames[cond]) == 1: # accomodates single trial data\n",
    "            to_plot = to_plot[np.newaxis, :]\n",
    "        \n",
    "        # plot the data\n",
    "        title = 'ROI {}; {}'.format(str(iROI), cond)\n",
    "        im = utils.subplot_heatmap(ax[subplot_index], title, to_plot, cmap='inferno', clims=clims, extent_=plot_extent)\n",
    "        \n",
    "        # add meta data lines\n",
    "        ax[subplot_index].axvline(0, color='0.5', alpha=1) # plot vertical line for time zero\n",
    "        ax[subplot_index].annotate('', xy=(event_bound_ratio[0], -0.01), xycoords='axes fraction', \n",
    "                                   xytext=(event_bound_ratio[1], -0.01), \n",
    "                                   arrowprops=dict(arrowstyle=\"-\", color='g'))\n",
    "        \n",
    "        \n",
    "        \n",
    "    cbar = fig.colorbar(im, ax = ax[subplot_index], shrink = 0.5)\n",
    "    cbar.ax.set_ylabel('Activity', fontsize = axis_label_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_subplots = len(conditions) + 1 # plus one for trial-avg traces\n",
    "n_columns = np.min([num_subplots, 4.0])\n",
    "n_rows = int(np.ceil(num_subplots/n_columns))\n",
    "\n",
    "for iROI in range(num_rois):\n",
    " \n",
    "    roi_clims = [ np.nanmin( [np.nanmin(data_dict[cond]['data'][...,iROI,:]) for cond in conditions] ), \n",
    "        np.nanmax( [np.nanmax(data_dict[cond]['data'][...,iROI,:]) for cond in conditions] ) ]\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=n_rows, ncols=int(n_columns), \n",
    "                           figsize=(n_columns*4, n_rows*3),\n",
    "                           constrained_layout=True)\n",
    "    \n",
    "    subplot_trial_heatmap(data_dict, conditions, tvec, event_bound_ratio, roi_clims, n_rows, n_columns, \n",
    "                           save_fig=False)\n",
    "    \n",
    "    ########## plot last subplot of trial-avg traces\n",
    "    \n",
    "    # determine subplot location index\n",
    "    subplot_index = subplot_loc(num_subplots-1, n_rows, n_columns)\n",
    "\n",
    "    for cond in conditions:\n",
    "        \n",
    "        # prep data to plot\n",
    "        num_trials = data_dict[cond]['num_trials']\n",
    "        to_plot = np.nanmean(data_dict[cond]['zdata'][:,iROI,:], axis=0)\n",
    "        to_plot_err = np.nanstd(data_dict[cond]['zdata'][:,iROI,:], axis=0)/np.sqrt(num_trials)\n",
    "        \n",
    "        # plot trace\n",
    "        ax[subplot_index].plot(tvec, to_plot)\n",
    "        if fparams['opto_blank_frame']: \n",
    "            ax[subplot_index].plot(tvec[t0_sample:event_end_sample], to_plot[t0_sample:event_end_sample], marker='.', color='g')\n",
    "        # plot shaded error\n",
    "        if fparams['flag_trial_avg_errbar']:\n",
    "            ax[subplot_index].fill_between(tvec, to_plot - to_plot_err, to_plot + to_plot_err,\n",
    "                         alpha=0.5) # this plots the shaded error bar\n",
    "        \n",
    "    # plot x, y labels, and legend\n",
    "    ax[subplot_index].set_ylabel('Z-Score Activity', fontsize=axis_label_size)\n",
    "    ax[subplot_index].set_xlabel('Time [s]', fontsize=axis_label_size)\n",
    "    ax[subplot_index].set_title('ROI # {}; Trial-avg'.format(str(iROI)), fontsize=axis_label_size)\n",
    "    ax[subplot_index].legend(conditions)\n",
    "    ax[subplot_index].autoscale(enable=True, axis='both', tight=True)\n",
    "    ax[subplot_index].axvline(0, color='0.5', alpha=0.65) # plot vertical line for time zero\n",
    "    ax[subplot_index].annotate('', xy=(event_bound_ratio[0], -0.01), xycoords='axes fraction', \n",
    "                                   xytext=(event_bound_ratio[1], -0.01), \n",
    "                                   arrowprops=dict(arrowstyle=\"-\", color='g'))\n",
    "    ax[subplot_index].tick_params(axis = 'both', which = 'major', labelsize = tick_font_size)\n",
    "    \n",
    "    for a in ax.flat[num_subplots:]:\n",
    "        a.axis('off')\n",
    "    \n",
    "    if fparams['flag_save_figs']:\n",
    "        fig.savefig( os.path.join(save_dir,'roi_{}_activity.png'.format(str(iROI))) ); \n",
    "        fig.savefig( os.path.join(save_dir,'roi_{}_activity.pdf'.format(str(iROI))) );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to find closest sample when a time occurs in a time vector\n",
    "tvec2samp = lambda tvec, time: np.argmin(np.abs(tvec - time))\n",
    "\n",
    "# function to sort ROIs based on activity in certain epoch\n",
    "def sort_heatmap_peaks(data, tvec, sort_epoch_start_time, sort_epoch_end_time, sort_method = 'peak_time'):\n",
    "    \n",
    "    # find start/end samples for epoch\n",
    "    sort_epoch_start_samp = tvec2samp(tvec, sort_epoch_start_time)\n",
    "    sort_epoch_end_samp = tvec2samp(tvec, sort_epoch_end_time)\n",
    "    \n",
    "    if sort_method == 'peak_time':\n",
    "        epoch_peak_samp = np.argmax(data[:,sort_epoch_start_samp:sort_epoch_end_samp], axis=1)\n",
    "        final_sorting = np.argsort(epoch_peak_samp)\n",
    "    elif sort_method == 'max_value':\n",
    " \n",
    "        time_max = np.nanmax(data[:,sort_epoch_start_samp:sort_epoch_end_samp], axis=1)\n",
    "        final_sorting = np.argsort(time_max)[::-1]\n",
    "\n",
    "    return final_sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if flag is true, sort ROIs (usually by average fluorescence within analysis window)\n",
    "if fparams['flag_sort_rois']:\n",
    "    if not fparams['roi_sort_cond']: # if no condition to sort by specified, use first condition\n",
    "        fparams['roi_sort_cond'] = data_dict.keys()[0]\n",
    "    if not fparams['roi_sort_cond'] in data_dict.keys():\n",
    "        sorted_roi_order = range(num_rois)\n",
    "        interesting_rois = fparams['interesting_rois']\n",
    "        print('Specified condition to sort by doesn\\'t exist!')\n",
    "    else:\n",
    "        # returns new order of rois sorted using the data and method supplied in the specified window\n",
    "        sorted_roi_order = sort_heatmap_peaks(data_dict[fparams['roi_sort_cond']]['ztrial_avg_data'], tvec, \n",
    "                           sort_epoch_start_time=0, \n",
    "                           sort_epoch_end_time = trial_start_end_sec[-1], \n",
    "                           sort_method = fparams['user_sort_method'])\n",
    "        # finds corresponding interesting roi (roi's to mark with an arrow) order after sorting\n",
    "        interesting_rois = np.in1d(sorted_roi_order, fparams['interesting_rois']).nonzero()[0] \n",
    "else:\n",
    "    sorted_roi_order = range(num_rois)\n",
    "    interesting_rois = fparams['interesting_rois']\n",
    "\n",
    "if not all_nan_rois[0].size == 0:\n",
    "    set_diff_keep_order = lambda main_list, remove_list : [i for i in main_list if i not in remove_list]\n",
    "    sorted_roi_order = set_diff_keep_order(sorted_roi_order, all_nan_rois)\n",
    "    interesting_rois = [i for i in fparams['interesting_rois'] if i not in all_nan_rois]\n",
    "    \n",
    "roi_order_path = os.path.join(fparams['fdir'], fparams['fname'] + '_roi_order.pkl')\n",
    "with open(roi_order_path, 'wb') as handle:\n",
    "     pickle.dump(sorted_roi_order, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_trial_avg_heatmap(data_in, conditions, tvec, event_bound_ratio, clims, sorted_roi_order = None, \n",
    "                           rois_oi = None, save_fig = False, axis_label_size=15):\n",
    "    \n",
    "    \"\"\"\n",
    "    Technically doesn't need to remove all_nan_rois b/c of nanmean calculations\n",
    "    \"\"\"\n",
    "    \n",
    "    num_subplots = len(conditions)\n",
    "    n_columns = np.min([num_subplots, 3.0])\n",
    "    n_rows = int(np.ceil(num_subplots/n_columns))\n",
    "\n",
    "    # set imshow extent to replace x and y axis ticks/labels (replace samples with time)\n",
    "    plot_extent = [tvec[0], tvec[-1], num_rois, 0 ]\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=n_rows, ncols=int(n_columns), figsize = (n_columns*5, n_rows*4))\n",
    "    if not isinstance(ax,np.ndarray): # this is here to make the code below compatible with indexing a single subplot object\n",
    "        ax = [ax]\n",
    "\n",
    "    for idx, cond in enumerate(conditions):\n",
    "\n",
    "        # determine subplot location index\n",
    "        if n_rows == 1:\n",
    "            subplot_index = idx\n",
    "        else:\n",
    "            subplot_index = np.unravel_index(idx, (n_rows, int(n_columns))) # turn int index to a tuple of array coordinates\n",
    "\n",
    "        # prep labels; plot x and y labels for first subplot\n",
    "        if subplot_index == (0, 0) or subplot_index == 0 :\n",
    "            ax[subplot_index].set_ylabel('ROI #', fontsize=axis_label_size)\n",
    "            ax[subplot_index].set_xlabel('Time [s]', fontsize=axis_label_size);\n",
    "        ax[subplot_index].tick_params(axis = 'both', which = 'major', labelsize = tick_font_size)\n",
    "        \n",
    "        # plot the data\n",
    "        if sorted_roi_order is not None:\n",
    "            roi_order = sorted_roi_order\n",
    "        else:\n",
    "            roi_order = slice(0, num_rois)\n",
    "        to_plot = data_in[cond]['ztrial_avg_data'][roi_order,:] # np.mean( data_dict[cond]['data'], axis=0) #\n",
    "\n",
    "        im = utils.subplot_heatmap(ax[subplot_index], cond, to_plot, clims = clims, extent_=plot_extent)\n",
    "        ax[subplot_index].axvline(0, color='k', alpha=0.3) # plot vertical line for time zero\n",
    "        ax[subplot_index].annotate('', xy=(event_bound_ratio[0], -0.01), xycoords='axes fraction', \n",
    "                                       xytext=(event_bound_ratio[1], -0.01), \n",
    "                                       arrowprops=dict(arrowstyle=\"-\", color='g'))\n",
    "        if rois_oi is not None:\n",
    "            for ROI_OI in rois_oi:\n",
    "                ax[subplot_index].annotate('', xy=(1.005, 1-(ROI_OI/num_rois)-0.015), xycoords='axes fraction', \n",
    "                                           xytext=(1.06, 1-(ROI_OI/num_rois)-0.015), \n",
    "                                           arrowprops=dict(arrowstyle=\"->\", color='k'))\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    cbar = fig.colorbar(im, ax = ax, shrink = 0.7)\n",
    "    cbar.ax.set_ylabel('Z-Score Activity', fontsize=13)\n",
    "    \n",
    "    # hide empty subplot\n",
    "    for a in ax.flat[num_subplots:]:\n",
    "        a.axis('off')\n",
    "    \n",
    "    if save_fig:\n",
    "        fig.savefig(os.path.join(save_dir,'trial_avg_heatmap.png')); \n",
    "        fig.savefig(os.path.join(save_dir,'trial_avg_heatmap.pdf'));\n",
    "\n",
    "plot_trial_avg_heatmap(data_dict, conditions, tvec, event_bound_ratio, clims = clims_z,\n",
    "                       sorted_roi_order = sorted_roi_order, rois_oi = interesting_rois, save_fig = fparams['flag_save_figs'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot trial- and ROI-averaged traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "line_shades = []\n",
    "fig, axs = plt.subplots(1,1, figsize = (10,6))\n",
    "for idx, cond in enumerate(conditions):\n",
    "    line_color = cmap_lines(idx)\n",
    "    # first trial avg the data\n",
    "    trial_avg = np.nanmean(data_dict[cond]['data'], axis=0)\n",
    "    \n",
    "    # z-score trial-avg data for each respective ROI\n",
    "    # apply zscore function to each row of data\n",
    "    app_axis = 1 \n",
    "    zscore_trial_avg = np.apply_along_axis(utils.zscore_, app_axis, trial_avg, baseline_svec)\n",
    "    \n",
    "    # take avg/std across ROIs\n",
    "    zscore_roi_trial_avg = np.nanmean(zscore_trial_avg, axis=0)\n",
    "    zscore_roi_trial_std = np.nanstd(zscore_trial_avg, axis=0)\n",
    "     \n",
    "    to_plot = np.squeeze(zscore_roi_trial_avg)\n",
    "    to_plot_err = np.squeeze(zscore_roi_trial_std)/np.sqrt(num_rois)\n",
    "    \n",
    "    axs.plot(tvec, to_plot, color=line_color)\n",
    "    if fparams['opto_blank_frame']:\n",
    "        line = axs.plot(tvec[t0_sample:event_end_sample], to_plot[t0_sample:event_end_sample], marker='.', color=line_color)\n",
    "    else:\n",
    "        line = axs.plot(tvec[t0_sample:event_end_sample], to_plot[t0_sample:event_end_sample], color=line_color)\n",
    "    \n",
    "    if fparams['flag_roi_trial_avg_errbar']:\n",
    "        shade = axs.fill_between(tvec, to_plot - to_plot_err, to_plot + to_plot_err, color = line_color,\n",
    "                     alpha=0.2) # this plots the shaded error bar\n",
    "        line_shades.append((line[0],shade))\n",
    "            \n",
    "axs.set_ylabel('Z-score Activity', fontsize=axis_label_size)\n",
    "axs.set_xlabel('Time [s]', fontsize=axis_label_size);\n",
    "axs.legend(conditions);\n",
    "axs.legend(line_shades, conditions, fontsize=15)\n",
    "axs.axvline(0, color='0.5', alpha=0.65) # plot vertical line for time zero\n",
    "axs.annotate('', xy=(event_bound_ratio[0], -0.01), xycoords='axes fraction', \n",
    "                               xytext=(event_bound_ratio[1], -0.01), \n",
    "                               arrowprops=dict(arrowstyle=\"-\", color='g'))\n",
    "axs.tick_params(axis = 'both', which = 'major', labelsize = tick_font_size+3)\n",
    "axs.autoscale(enable=True, axis='both', tight=True)\n",
    "\n",
    "#axs.set_ylim([-1.5, 10])\n",
    "\n",
    "if fparams['flag_save_figs']:\n",
    "        fig.savefig(os.path.join(save_dir,'roi_trial_avg_trace.png')); fig.savefig(os.path.join(save_dir,'roi_trial_avg_trace.pdf'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for finding the index of the closest entry in an array to a provided value\n",
    "def find_nearest_idx(array, value):\n",
    "\n",
    "    if isinstance(array, pd.Series):\n",
    "        idx = (np.abs(array - value)).idxmin()\n",
    "        return idx, array.index.get_loc(idx), array[idx] # series index, 0-relative index, entry value\n",
    "    else:\n",
    "        array = np.asarray(array)\n",
    "        idx = (np.abs(array - value)).argmin()\n",
    "        return idx, array[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_window = [0.2, 5]\n",
    "analysis_win_samps = [ find_nearest_idx(tvec, time)[0] for time in analysis_window ]\n",
    "\n",
    "to_plot = []\n",
    "to_plot_err = []\n",
    "\n",
    "fig, axs = plt.subplots(1,1, figsize = (5,5))\n",
    "for idx, cond in enumerate(conditions):\n",
    "    line_color = cmap_lines(idx)\n",
    "    # first trial avg the data\n",
    "    trial_avg = np.nanmean(data_dict[cond]['data'], axis=0)\n",
    "    \n",
    "    # z-score trial-avg data for each respective ROI\n",
    "    # apply zscore function to each row of data\n",
    "    app_axis = 1 \n",
    "    zscore_trial_avg = np.apply_along_axis(utils.zscore_, app_axis, trial_avg, baseline_svec)\n",
    "    \n",
    "    # take avg across time\n",
    "    zscore_trial_time_avg = np.nanmean(zscore_trial_avg[:,analysis_win_samps[0]:analysis_win_samps[1],:], axis=1)\n",
    "    \n",
    "    # take avg/std across ROIs\n",
    "    zscore_roi_trial_time_avg = np.nanmean(zscore_trial_time_avg[:5], axis=0)\n",
    "    zscore_roi_trial_time_std = np.nanstd(zscore_trial_time_avg[:5], axis=0)\n",
    "     \n",
    "    to_plot.append(zscore_roi_trial_time_avg[0])\n",
    "    to_plot_err.append(zscore_roi_trial_time_std[0]/np.sqrt(3))\n",
    "    \n",
    "barlist = axs.bar(conditions, to_plot, yerr=to_plot_err, align='center', alpha=0.5, ecolor='black', capsize=10 )\n",
    "for idx in range(len(conditions)):\n",
    "    barlist[idx].set_color(cmap_lines(idx))\n",
    "axs.set_ylabel('Normalized Fluorescence', fontsize=13)\n",
    "axs.set_title('ROI-, Trial-, Time-averaged Quant', fontsize=15)\n",
    "axs.yaxis.grid(True)\n",
    "axs.tick_params(axis = 'both', which = 'major', labelsize = tick_font_size)\n",
    "axs.tick_params(axis = 'x', which = 'major', rotation = 45)\n",
    "# Save the figure and show\n",
    "plt.tight_layout()\n",
    "\n",
    "if fparams['flag_save_figs']:\n",
    "    fig.savefig(os.path.join(save_dir,'roi_trial_time_avg_bar.png')); \n",
    "    fig.savefig(os.path.join(save_dir,'roi_trial_time_avg_bar.pdf'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
